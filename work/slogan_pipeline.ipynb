{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class text_processor:\n",
    "\n",
    "    def __init__(self, remover_function=None, tokenizer_function=None, \n",
    "                 cleaning_function=None, stemmer_function=None,\n",
    "                     vectorizer_function = CountVectorizer()):\n",
    "        self.remover = remover_function\n",
    "        self.tokenizer = tokenizer_function\n",
    "        self.cleaner = cleaning_function\n",
    "        self.stemmer = stemmer_function\n",
    "        self.vectorizer = vectorizer_function\n",
    "\n",
    "\n",
    "        if remover_function == 'no_punctuation':\n",
    "            self.remover = self.no_punctuation\n",
    "        if tokenizer_function == 'tk_word':\n",
    "            self.tokenizer = self.tk_word\n",
    "        if not tokenizer_function:\n",
    "            self.tokenizer = self.splitter\n",
    "        if cleaning_function == 'lowstem':\n",
    "            self.cleaner = self.lowstem\n",
    "                \n",
    "   # cleaning functions\n",
    "\n",
    "    def lower(self,X):\n",
    "        sentences = []\n",
    "        for sentence in X:\n",
    "            sentences.append(sentence.lower()) \n",
    "        return sentences\n",
    "\n",
    "\n",
    "    def no_punctuation(self,X):\n",
    "    # remove the punctuation\n",
    "        pos = []\n",
    "        for sentence in X:\n",
    "            for punc in string.punctuation:\n",
    "                sentence = sentence.replace(punc,'')\n",
    "            pos.append(sentence)\n",
    "        return pos\n",
    "    \n",
    " # tokenizer functions   \n",
    "    \n",
    "    def tk_word(self,X):\n",
    "        vocabulary = []\n",
    "        for x in X:\n",
    "            vocabulary.append(word_tokenize(x)) \n",
    "        return vocabulary        \n",
    "    \n",
    "    \n",
    "    def splitter(self, text):\n",
    "        \"\"\"\n",
    "        Default tokenizer that splits on spaces naively\n",
    "        \"\"\"\n",
    "        return text.split(' ')\n",
    "\n",
    "   # stemmer function\n",
    "    \n",
    "\n",
    "    def stem(self,X):\n",
    "        stemmed = []\n",
    "        for word in (X):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            stemmed.append(stem_word)\n",
    "        return stemmed\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # vectorizing function\n",
    "    def vectorize(self, X):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.columns=self.vectorizer.get_feature_names()\n",
    "        return self.vectorizer.transform(X).toarray()\n",
    "        \n",
    "        \n",
    "    def fit(self,X):\n",
    "        clear_text = self.remover(X)\n",
    "        clear_text = self.lower(clear_text)\n",
    "#        clear_text = self.stem(clear_text)\n",
    "        self.matrix = self.vectorize(clear_text)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = text_processor(remover_function='no_punctuation',tokenizer_function = 'tk_word'\n",
    "                    ,stemmer_function = PorterStemmer,\n",
    "#                    vectorizer_function=TfidfVectorizer(min_df=0.3, max_df=0.8))\n",
    "                    vectorizer_function=TfidfVectorizer(min_df=0, max_df=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slogans = ['extending and enhancing human life', \n",
    "           'We will Be There When The Light Goes On', 'Small Business, rejoice']\n",
    "bukowski = ['the impossibility of being human','moving this little bit of light toward us']\n",
    "ensemble = ['extending and enhancing human life', \n",
    "           'We will Be There When The Light Goes On', 'Small Business, rejoice',\n",
    "            'the impossibility of being human','moving this little bit of light toward us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.fit(slogans)\n",
    "slogans_matrix = nlp.matrix\n",
    "slogans_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.fit(bukowski)\n",
    "bukowski_matrix = nlp.matrix\n",
    "bukowski_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = bukowski + slogans\n",
    "nlp.fit(ensemble)\n",
    "ensemble_matrix = nlp.matrix\n",
    "ensemble_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'be',\n",
       " 'being',\n",
       " 'bit',\n",
       " 'business',\n",
       " 'enhancing',\n",
       " 'extending',\n",
       " 'goes',\n",
       " 'impossibility',\n",
       " 'life',\n",
       " 'little',\n",
       " 'moving',\n",
       " 'on',\n",
       " 'rejoice',\n",
       " 'small',\n",
       " 'there',\n",
       " 'this',\n",
       " 'toward',\n",
       " 'us',\n",
       " 'we',\n",
       " 'when',\n",
       " 'will']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.70710678, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.40824829, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.40824829, 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.40824829, 0.40824829, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5       , 0.5       , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.37796447, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37796447, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37796447, 0.        , 0.        ,\n",
       "        0.37796447, 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.37796447, 0.37796447],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57735027, 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "lsa = TruncatedSVD(2, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(ensemble_matrix)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18098099, 0.20284924])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>be</th>\n",
       "      <th>being</th>\n",
       "      <th>bit</th>\n",
       "      <th>business</th>\n",
       "      <th>enhancing</th>\n",
       "      <th>extending</th>\n",
       "      <th>goes</th>\n",
       "      <th>impossibility</th>\n",
       "      <th>life</th>\n",
       "      <th>...</th>\n",
       "      <th>on</th>\n",
       "      <th>rejoice</th>\n",
       "      <th>small</th>\n",
       "      <th>there</th>\n",
       "      <th>this</th>\n",
       "      <th>toward</th>\n",
       "      <th>us</th>\n",
       "      <th>we</th>\n",
       "      <th>when</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.11933</td>\n",
       "      <td>-0.03403</td>\n",
       "      <td>0.04327</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.55713</td>\n",
       "      <td>0.11933</td>\n",
       "      <td>0.11933</td>\n",
       "      <td>-0.03403</td>\n",
       "      <td>0.04327</td>\n",
       "      <td>0.11933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03403</td>\n",
       "      <td>0.55713</td>\n",
       "      <td>0.55713</td>\n",
       "      <td>-0.03403</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>-0.03403</td>\n",
       "      <td>-0.03403</td>\n",
       "      <td>-0.03403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>0.33811</td>\n",
       "      <td>0.25388</td>\n",
       "      <td>-0.20508</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>-0.04976</td>\n",
       "      <td>0.33811</td>\n",
       "      <td>0.33811</td>\n",
       "      <td>0.25388</td>\n",
       "      <td>-0.20508</td>\n",
       "      <td>0.33811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25388</td>\n",
       "      <td>-0.04976</td>\n",
       "      <td>-0.04976</td>\n",
       "      <td>0.25388</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>-0.00026</td>\n",
       "      <td>0.25388</td>\n",
       "      <td>0.25388</td>\n",
       "      <td>0.25388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 and       be    being      bit  business  enhancing  \\\n",
       "component_1  0.11933 -0.03403  0.04327  0.00004   0.55713    0.11933   \n",
       "component_2  0.33811  0.25388 -0.20508 -0.00026  -0.04976    0.33811   \n",
       "\n",
       "             extending     goes  impossibility     life   ...          on  \\\n",
       "component_1    0.11933 -0.03403        0.04327  0.11933   ...    -0.03403   \n",
       "component_2    0.33811  0.25388       -0.20508  0.33811   ...     0.25388   \n",
       "\n",
       "             rejoice    small    there     this   toward       us       we  \\\n",
       "component_1  0.55713  0.55713 -0.03403  0.00004  0.00004  0.00004 -0.03403   \n",
       "component_2 -0.04976 -0.04976  0.25388 -0.00026 -0.00026 -0.00026  0.25388   \n",
       "\n",
       "                when     will  \n",
       "component_1 -0.03403 -0.03403  \n",
       "component_2  0.25388  0.25388  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(lsa.components_.round(5),\n",
    "             index = [\"component_1\",\"component_2\"],columns = ensemble_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(dtm_lsa.round(5), index = ensemble, columns = [\"component_1\",\"component_2\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the impossibility of being human</td>\n",
       "      <td>0.20644</td>\n",
       "      <td>-0.97846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moving this little bit of light toward us</td>\n",
       "      <td>0.14930</td>\n",
       "      <td>-0.98879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extending and enhancing human life</td>\n",
       "      <td>0.33281</td>\n",
       "      <td>0.94300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We will Be There When The Light Goes On</td>\n",
       "      <td>-0.13284</td>\n",
       "      <td>0.99114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Small Business, rejoice</td>\n",
       "      <td>0.99604</td>\n",
       "      <td>-0.08895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       index  component_1  component_2\n",
       "0           the impossibility of being human      0.20644     -0.97846\n",
       "1  moving this little bit of light toward us      0.14930     -0.98879\n",
       "2         extending and enhancing human life      0.33281      0.94300\n",
       "3    We will Be There When The Light Goes On     -0.13284      0.99114\n",
       "4                    Small Business, rejoice      0.99604     -0.08895"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (df3['index'] == \"moving this little bit of light toward us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[mask1].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Small Business, rejoice</td>\n",
       "      <td>0.99604</td>\n",
       "      <td>-0.08895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extending and enhancing human life</td>\n",
       "      <td>0.33281</td>\n",
       "      <td>0.94300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                index  component_1  component_2\n",
       "4             Small Business, rejoice      0.99604     -0.08895\n",
       "2  extending and enhancing human life      0.33281      0.94300"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.nlargest(2, 'component_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moving this little bit of light toward us'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.iloc[1]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>We will Be There When The Light Goes On</th>\n",
       "      <td>-0.13284</td>\n",
       "      <td>0.99114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extending and enhancing human life</th>\n",
       "      <td>0.33281</td>\n",
       "      <td>0.94300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         component_1  component_2\n",
       "We will Be There When The Light Goes On     -0.13284      0.99114\n",
       "extending and enhancing human life           0.33281      0.94300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.nlargest(2, 'component_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.nlargest(2, 'component_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We will Be There When The Light Goes On'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extending and enhancing human life'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((len(df4.index[1].split())+len(df4.index[1].split()))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extending', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('enhancing', 'VBG'),\n",
       " ('human', 'JJ'),\n",
       " ('life', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(df4.index[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('Be', 'VB'),\n",
       " ('There', 'EX'),\n",
       " ('When', 'WRB'),\n",
       " ('The', 'DT'),\n",
       " ('Light', 'NNP'),\n",
       " ('Goes', 'NNP'),\n",
       " ('On', 'IN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(df4.index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/aug18slogan.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['SLOGAN']\n",
    "pos = ['the impossibility of being human']\n",
    "for x in X:\n",
    "    for punc in string.punctuation:\n",
    "        x = x.replace(punc,'')\n",
    "    pos.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.fit(pos)\n",
    "pos_matrix = nlp.matrix\n",
    "pos_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['130',\n",
       " '160',\n",
       " '1888',\n",
       " '1897',\n",
       " '30',\n",
       " '50',\n",
       " '99',\n",
       " 'abc',\n",
       " 'absolutely',\n",
       " 'accelerate',\n",
       " 'achieve',\n",
       " 'acquisitions',\n",
       " 'act',\n",
       " 'action',\n",
       " 'add',\n",
       " 'advance',\n",
       " 'advances',\n",
       " 'advantage',\n",
       " 'advertise',\n",
       " 'advisor',\n",
       " 'aep',\n",
       " 'after',\n",
       " 'agencies',\n",
       " 'aggression',\n",
       " 'aimco',\n",
       " 'alleviating',\n",
       " 'alone',\n",
       " 'alongside',\n",
       " 'ambition',\n",
       " 'american',\n",
       " 'animals',\n",
       " 'anticipate',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appreciating',\n",
       " 'arbys',\n",
       " 'arent',\n",
       " 'arizona',\n",
       " 'assurant',\n",
       " 'authoritative',\n",
       " 'auto',\n",
       " 'awake',\n",
       " 'baby',\n",
       " 'bad',\n",
       " 'balance',\n",
       " 'banking',\n",
       " 'banks',\n",
       " 'banquet',\n",
       " 'bar',\n",
       " 'bean',\n",
       " 'beanz',\n",
       " 'beautify',\n",
       " 'beer',\n",
       " 'begins',\n",
       " 'behind',\n",
       " 'believing',\n",
       " 'benefits',\n",
       " 'bestseller',\n",
       " 'bettering',\n",
       " 'between',\n",
       " 'birth',\n",
       " 'bond',\n",
       " 'born',\n",
       " 'boy',\n",
       " 'breakfast',\n",
       " 'breakthrough',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'brighter',\n",
       " 'brilliance',\n",
       " 'brilliant',\n",
       " 'brings',\n",
       " 'bubbles',\n",
       " 'buid',\n",
       " 'builder',\n",
       " 'burger',\n",
       " 'but',\n",
       " 'button',\n",
       " 'buying',\n",
       " 'cabinets',\n",
       " 'cable',\n",
       " 'call',\n",
       " 'camel',\n",
       " 'canthe',\n",
       " 'capture',\n",
       " 'cartoons',\n",
       " 'caveman',\n",
       " 'cbs',\n",
       " 'cereal',\n",
       " 'challenging',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changing',\n",
       " 'charmin',\n",
       " 'checks',\n",
       " 'cheers',\n",
       " 'chic',\n",
       " 'chicken',\n",
       " 'chikin',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'chubb',\n",
       " 'citizenship',\n",
       " 'clean',\n",
       " 'cleaner',\n",
       " 'climate',\n",
       " 'climbing',\n",
       " 'close',\n",
       " 'coach',\n",
       " 'cola',\n",
       " 'collection',\n",
       " 'commercial',\n",
       " 'commitment',\n",
       " 'companies',\n",
       " 'computing',\n",
       " 'conagra',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'connects',\n",
       " 'consider',\n",
       " 'consulting',\n",
       " 'convenience',\n",
       " 'copper',\n",
       " 'cost',\n",
       " 'counts',\n",
       " 'creating',\n",
       " 'credit',\n",
       " 'cremo',\n",
       " 'cummins',\n",
       " 'cup',\n",
       " 'dabll',\n",
       " 'daily',\n",
       " 'data',\n",
       " 'deep',\n",
       " 'deere',\n",
       " 'defining',\n",
       " 'delight',\n",
       " 'delivery',\n",
       " 'dell',\n",
       " 'demanding',\n",
       " 'dentistry',\n",
       " 'depend',\n",
       " 'deposits',\n",
       " 'deserve',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'desk',\n",
       " 'destination',\n",
       " 'develop',\n",
       " 'devices',\n",
       " 'diamond',\n",
       " 'discovered',\n",
       " 'discovering',\n",
       " 'discovery',\n",
       " 'disney',\n",
       " 'dividend',\n",
       " 'dna',\n",
       " 'document',\n",
       " 'dominos',\n",
       " 'done',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'dress',\n",
       " 'dressing',\n",
       " 'drive',\n",
       " 'drivers',\n",
       " 'drop',\n",
       " 'druggist',\n",
       " 'earth',\n",
       " 'earthmoving',\n",
       " 'easier',\n",
       " 'ebusiness',\n",
       " 'edge',\n",
       " 'efficiency',\n",
       " 'electromechanical',\n",
       " 'electronic',\n",
       " 'else',\n",
       " 'emotionally',\n",
       " 'empower',\n",
       " 'enduring',\n",
       " 'energizing',\n",
       " 'engage',\n",
       " 'engaging',\n",
       " 'engineering',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertain',\n",
       " 'envy',\n",
       " 'eog',\n",
       " 'equation',\n",
       " 'essential',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'evolve',\n",
       " 'exceed',\n",
       " 'expectations',\n",
       " 'experiences',\n",
       " 'expertise',\n",
       " 'exploration',\n",
       " 'explore',\n",
       " 'express',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fail',\n",
       " 'family',\n",
       " 'fares',\n",
       " 'fastest',\n",
       " 'favors',\n",
       " 'fedex',\n",
       " 'feels',\n",
       " 'fiat',\n",
       " 'fill',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'finding',\n",
       " 'finger',\n",
       " 'fire',\n",
       " 'firstalways',\n",
       " 'fizz',\n",
       " 'fizzical',\n",
       " 'floor',\n",
       " 'fluent',\n",
       " 'focused',\n",
       " 'folgers',\n",
       " 'folks',\n",
       " 'follows',\n",
       " 'footprint',\n",
       " 'footprints',\n",
       " 'forget',\n",
       " 'forgotten',\n",
       " 'fragrance',\n",
       " 'freedom',\n",
       " 'fresh',\n",
       " 'friday',\n",
       " 'frontier',\n",
       " 'frontiers',\n",
       " 'fuel',\n",
       " 'fuelling',\n",
       " 'fullest',\n",
       " 'fully',\n",
       " 'fullyintegrated',\n",
       " 'gain',\n",
       " 'games',\n",
       " 'gap',\n",
       " 'generate',\n",
       " 'generation',\n",
       " 'getting',\n",
       " 'goes',\n",
       " 'gold',\n",
       " 'greatest',\n",
       " 'greener',\n",
       " 'grid',\n",
       " 'growth',\n",
       " 'guidance',\n",
       " 'guys',\n",
       " 'had',\n",
       " 'hanes',\n",
       " 'happen',\n",
       " 'happiness',\n",
       " 'hard',\n",
       " 'harder',\n",
       " 'has',\n",
       " 'hasbro',\n",
       " 'he',\n",
       " 'healthier',\n",
       " 'healthy',\n",
       " 'heard',\n",
       " 'heartland',\n",
       " 'heaven',\n",
       " 'heights',\n",
       " 'heinz',\n",
       " 'hellmanns',\n",
       " 'hello',\n",
       " 'helps',\n",
       " 'hemodynamic',\n",
       " 'her',\n",
       " 'hide',\n",
       " 'history',\n",
       " 'hooked',\n",
       " 'hope',\n",
       " 'house',\n",
       " 'hr',\n",
       " 'humane',\n",
       " 'hungry',\n",
       " 'ibm',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'image',\n",
       " 'imagine',\n",
       " 'important',\n",
       " 'impossibility',\n",
       " 'impression',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'included',\n",
       " 'income',\n",
       " 'index',\n",
       " 'individual',\n",
       " 'industry',\n",
       " 'infosys',\n",
       " 'infrastructure',\n",
       " 'ingenuity',\n",
       " 'innovators',\n",
       " 'inside',\n",
       " 'inspiration',\n",
       " 'inspire',\n",
       " 'institutions',\n",
       " 'instruments',\n",
       " 'insure',\n",
       " 'insured',\n",
       " 'integrated',\n",
       " 'intel',\n",
       " 'intellect',\n",
       " 'intentional',\n",
       " 'into',\n",
       " 'intrests',\n",
       " 'invent',\n",
       " 'inventing',\n",
       " 'invesco',\n",
       " 'invest',\n",
       " 'invested',\n",
       " 'investors',\n",
       " 'itself',\n",
       " 'ivory',\n",
       " 'jeans',\n",
       " 'jello',\n",
       " 'job',\n",
       " 'journey',\n",
       " 'joy',\n",
       " 'kansas',\n",
       " 'kat',\n",
       " 'kay',\n",
       " 'keeps',\n",
       " 'kid',\n",
       " 'king',\n",
       " 'kiss',\n",
       " 'kit',\n",
       " 'klondike',\n",
       " 'kotak',\n",
       " 'lager',\n",
       " 'land',\n",
       " 'las',\n",
       " 'last',\n",
       " 'lauren',\n",
       " 'lickin',\n",
       " 'light',\n",
       " 'llife',\n",
       " 'locally',\n",
       " 'locations',\n",
       " 'logistics',\n",
       " 'london',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looks',\n",
       " 'lovin',\n",
       " 'lower',\n",
       " 'lowering',\n",
       " 'luxurious',\n",
       " 'made',\n",
       " 'madness',\n",
       " 'manages',\n",
       " 'managing',\n",
       " 'manufacturer',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'markets',\n",
       " 'mattel',\n",
       " 'max',\n",
       " 'maybe',\n",
       " 'maybelline',\n",
       " 'mccormick',\n",
       " 'meaningful',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'meanz',\n",
       " 'measurement',\n",
       " 'media',\n",
       " 'medicine',\n",
       " 'melts',\n",
       " 'merchant',\n",
       " 'met',\n",
       " 'metlife',\n",
       " 'middle',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'milk',\n",
       " 'million',\n",
       " 'mind',\n",
       " 'mindguaranteed',\n",
       " 'mindset',\n",
       " 'minimum',\n",
       " 'minutes',\n",
       " 'miracles',\n",
       " 'mission',\n",
       " 'mm',\n",
       " 'mobility',\n",
       " 'modern',\n",
       " 'moments',\n",
       " 'monitoring',\n",
       " 'monthly',\n",
       " 'mor',\n",
       " 'most',\n",
       " 'mouth',\n",
       " 'moved',\n",
       " 'mtv',\n",
       " 'my',\n",
       " 'natural',\n",
       " 'neighbors',\n",
       " 'networking',\n",
       " 'newer',\n",
       " 'news',\n",
       " 'nourish',\n",
       " 'nourishing',\n",
       " 'obsessed',\n",
       " 'obsession',\n",
       " 'odds',\n",
       " 'once',\n",
       " 'ones',\n",
       " 'open',\n",
       " 'opening',\n",
       " 'optimization',\n",
       " 'or',\n",
       " 'oracle',\n",
       " 'other',\n",
       " 'overnight',\n",
       " 'pain',\n",
       " 'passed',\n",
       " 'passionate',\n",
       " 'pause',\n",
       " 'payments',\n",
       " 'payroll',\n",
       " 'pays',\n",
       " 'peace',\n",
       " 'pentair',\n",
       " 'peoplecentered',\n",
       " 'pepsi',\n",
       " 'per',\n",
       " 'percent',\n",
       " 'perfection',\n",
       " 'perform',\n",
       " 'perspective',\n",
       " 'petroleum',\n",
       " 'pfizer',\n",
       " 'pharmacy',\n",
       " 'philosophy',\n",
       " 'pictures',\n",
       " 'pioneering',\n",
       " 'pizza',\n",
       " 'plan',\n",
       " 'planned',\n",
       " 'play',\n",
       " 'played',\n",
       " 'players',\n",
       " 'playing',\n",
       " 'please',\n",
       " 'plop',\n",
       " 'possibilities',\n",
       " 'possibility',\n",
       " 'powerful',\n",
       " 'powers',\n",
       " 'predictability',\n",
       " 'prepared',\n",
       " 'prescription',\n",
       " 'prices',\n",
       " 'pride',\n",
       " 'prime',\n",
       " 'pro',\n",
       " 'probably',\n",
       " 'productive',\n",
       " 'professional',\n",
       " 'profit',\n",
       " 'profitably',\n",
       " 'programmable',\n",
       " 'progress',\n",
       " 'promises',\n",
       " 'ps',\n",
       " 'publishing',\n",
       " 'purity',\n",
       " 'pursuit',\n",
       " 'push',\n",
       " 'puts',\n",
       " 'qs',\n",
       " 'raising',\n",
       " 'ralph',\n",
       " 'rates',\n",
       " 'reach',\n",
       " 'reaching',\n",
       " 'read',\n",
       " 'reality',\n",
       " 'reason',\n",
       " 'rebel',\n",
       " 'records',\n",
       " 'redefined',\n",
       " 'redefining',\n",
       " 'reducing',\n",
       " 'reflect',\n",
       " 'refreshes',\n",
       " 'reinvent',\n",
       " 'reinventing',\n",
       " 'reit',\n",
       " 'rejoice',\n",
       " 'relationship',\n",
       " 'relax',\n",
       " 'reliable',\n",
       " 'relief',\n",
       " 'remembered',\n",
       " 'renewed',\n",
       " 'resource',\n",
       " 'resourceful',\n",
       " 'resources',\n",
       " 'respectteamwork',\n",
       " 'responsible',\n",
       " 'responsibly',\n",
       " 'restoring',\n",
       " 'retirement',\n",
       " 'revolves',\n",
       " 'rising',\n",
       " 'risk',\n",
       " 'risks',\n",
       " 'road',\n",
       " 'roads',\n",
       " 'romancing',\n",
       " 'room',\n",
       " 'route',\n",
       " 'royalty',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'safely',\n",
       " 'salt',\n",
       " 'sanitizing',\n",
       " 'saving',\n",
       " 'say',\n",
       " 'scale',\n",
       " 'second',\n",
       " 'seeing',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'served',\n",
       " 'sets',\n",
       " 'settle',\n",
       " 'sexy',\n",
       " 'shaping',\n",
       " 'sherwinwilliams',\n",
       " 'shes',\n",
       " 'ship',\n",
       " 'shipping',\n",
       " 'shop',\n",
       " 'shopping',\n",
       " 'short',\n",
       " 'shortest',\n",
       " 'sign',\n",
       " 'signalprocessing',\n",
       " 'significant',\n",
       " 'silk',\n",
       " 'simple',\n",
       " 'simplifying',\n",
       " 'sixth',\n",
       " 'skywards',\n",
       " 'sleeps',\n",
       " 'smile',\n",
       " 'smiles',\n",
       " 'smooth',\n",
       " 'snack',\n",
       " 'so',\n",
       " 'soap',\n",
       " 'software',\n",
       " 'solar',\n",
       " 'solid',\n",
       " 'solved',\n",
       " 'some',\n",
       " 'someone',\n",
       " 'sound',\n",
       " 'soup',\n",
       " 'spirit',\n",
       " 'spit',\n",
       " 'squeeze',\n",
       " 'staffing',\n",
       " 'standard',\n",
       " 'starts',\n",
       " 'stay',\n",
       " 'stock',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'straight',\n",
       " 'strategic',\n",
       " 'strategy',\n",
       " 'strength',\n",
       " 'suntrust',\n",
       " 'supplies',\n",
       " 'supply',\n",
       " 'surface',\n",
       " 'surprised',\n",
       " 'sweetest',\n",
       " 'symantec',\n",
       " 'sysco',\n",
       " 'talk',\n",
       " 'tank',\n",
       " 'terms',\n",
       " 'thats',\n",
       " 'their',\n",
       " 'themselves',\n",
       " 'therapeutics',\n",
       " 'therefore',\n",
       " 'theresÿmastercard',\n",
       " 'thing',\n",
       " 'thoroughbred',\n",
       " 'thought',\n",
       " 'tiger',\n",
       " 'tightest',\n",
       " 'todays',\n",
       " 'tomorrows',\n",
       " 'top',\n",
       " 'touching',\n",
       " 'tough',\n",
       " 'toughest',\n",
       " 'toy',\n",
       " 'transfarency',\n",
       " 'transportation',\n",
       " 'trip',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'trusted',\n",
       " 'trusts',\n",
       " 'try',\n",
       " 'turn',\n",
       " 'tyson',\n",
       " 'unbeatable',\n",
       " 'under',\n",
       " 'understanding',\n",
       " 'unique',\n",
       " 'unleash',\n",
       " 'unleashing',\n",
       " 'unlimited',\n",
       " 'unparalleled',\n",
       " 'use',\n",
       " 'user',\n",
       " 'valves',\n",
       " 'vant',\n",
       " 'vegas',\n",
       " 'verisign',\n",
       " 'visa',\n",
       " 'wait',\n",
       " 'waking',\n",
       " 'walk',\n",
       " 'walking',\n",
       " 'wallet',\n",
       " 'wanted',\n",
       " 'ways',\n",
       " 'wealth',\n",
       " 'wherever',\n",
       " 'which',\n",
       " 'whiskey',\n",
       " 'whopper',\n",
       " 'whos',\n",
       " 'wins',\n",
       " 'within',\n",
       " 'women',\n",
       " 'workday',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'wouldnt',\n",
       " 'writing',\n",
       " 'wynn',\n",
       " 'ya',\n",
       " 'yield',\n",
       " 'youd',\n",
       " 'yours',\n",
       " 'youve',\n",
       " 'yum',\n",
       " 'zone']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
