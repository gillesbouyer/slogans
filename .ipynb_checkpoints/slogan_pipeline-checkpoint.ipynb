{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class text_processor:\n",
    "\n",
    "    def __init__(self, remover_function=None, tokenizer_function=None, \n",
    "                 cleaning_function=None, stemmer_function=None,\n",
    "                     vectorizer_function = CountVectorizer()):\n",
    "        self.remover = remover_function\n",
    "        self.tokenizer = tokenizer_function\n",
    "        self.cleaner = cleaning_function\n",
    "        self.stemmer = stemmer_function\n",
    "        self.vectorizer = vectorizer_function\n",
    "\n",
    "\n",
    "        if remover_function == 'no_punctuation':\n",
    "            self.remover = self.no_punctuation\n",
    "        if tokenizer_function == 'tk_word':\n",
    "            self.tokenizer = self.tk_word\n",
    "        if not tokenizer_function:\n",
    "            self.tokenizer = self.splitter\n",
    "        if cleaning_function == 'lowstem':\n",
    "            self.cleaner = self.lowstem\n",
    "\n",
    "    def stem(self,X):\n",
    "        stemmed = []\n",
    "        for word in (X):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            stemmed.append(stem_word)\n",
    "        return stemmed\n",
    "\n",
    "                \n",
    "   # cleaning functions\n",
    "\n",
    "    def lower(self,X):\n",
    "        sentences = []\n",
    "        for sentence in X:\n",
    "            sentences.append(sentence.lower()) \n",
    "        return sentences\n",
    "\n",
    "\n",
    "    def no_punctuation(self,X):\n",
    "    # remove the punctuation\n",
    "        pos = []\n",
    "        for sentence in X:\n",
    "            for punc in string.punctuation:\n",
    "                sentence = sentence.replace(punc,'')\n",
    "            pos.append(sentence)\n",
    "        return pos\n",
    "    \n",
    " # tokenizer functions   \n",
    "    \n",
    "    def tk_word(self,X):\n",
    "        vocabulary = []\n",
    "        for x in X:\n",
    "            vocabulary.append(word_tokenize(x)) \n",
    "        return vocabulary        \n",
    "    \n",
    "    \n",
    "    def splitter(self, text):\n",
    "        \"\"\"\n",
    "        Default tokenizer that splits on spaces naively\n",
    "        \"\"\"\n",
    "        return text.split(' ')\n",
    "\n",
    "   # stemmer function\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # vectorizing function\n",
    "    def vectorize(self, X):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.columns=self.vectorizer.get_feature_names()\n",
    "        return self.vectorizer.transform(X).toarray()\n",
    "        \n",
    "        \n",
    "    def fit(self,X):\n",
    "        clear_text = self.remover(X)\n",
    "        clear_text = self.lower(clear_text)\n",
    "#        clear_text = self.stem(clear_text)\n",
    "        self.matrix = self.vectorize(clear_text)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = text_processor(remover_function='no_punctuation',tokenizer_function = 'tk_word'\n",
    "                    ,stemmer_function = PorterStemmer,\n",
    "#                    vectorizer_function=TfidfVectorizer(min_df=0.3, max_df=0.8))\n",
    "                    vectorizer_function=TfidfVectorizer(min_df=0.1, max_df=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slogans = ['extending and enhancing human life', \n",
    "           'We will Be There When The Light Goes On', 'Small Business, rejoice']\n",
    "bukowski = ['the impossibility of being human','moving this little bit of light toward us']\n",
    "ensemble = ['extending and enhancing human life', \n",
    "           'We will Be There When The Light Goes On', 'Small Business, rejoice',\n",
    "            'the impossibility of being human','moving this little bit of light toward us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.fit(slogans)\n",
    "slogans_matrix = nlp.matrix\n",
    "slogans_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.fit(bukowski)\n",
    "bukowski_matrix = nlp.matrix\n",
    "bukowski_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = bukowski + slogans\n",
    "nlp.fit(ensemble)\n",
    "ensemble_matrix = nlp.matrix\n",
    "ensemble_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'be',\n",
       " 'being',\n",
       " 'bit',\n",
       " 'business',\n",
       " 'enhancing',\n",
       " 'extending',\n",
       " 'goes',\n",
       " 'human',\n",
       " 'impossibility',\n",
       " 'life',\n",
       " 'light',\n",
       " 'little',\n",
       " 'moving',\n",
       " 'of',\n",
       " 'on',\n",
       " 'rejoice',\n",
       " 'small',\n",
       " 'the',\n",
       " 'there',\n",
       " 'this',\n",
       " 'toward',\n",
       " 'us',\n",
       " 'we',\n",
       " 'when',\n",
       " 'will']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.50297966, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40580082, 0.50297966,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40580082,\n",
       "        0.        , 0.        , 0.        , 0.40580082, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.37007017, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29857028, 0.37007017, 0.37007017, 0.29857028,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.37007017, 0.37007017, 0.37007017, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.46369322, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46369322, 0.46369322, 0.        , 0.37410477, 0.        ,\n",
       "        0.46369322, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.34706676, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34706676, 0.        , 0.        ,\n",
       "        0.        , 0.28001128, 0.        , 0.        , 0.        ,\n",
       "        0.34706676, 0.        , 0.        , 0.28001128, 0.34706676,\n",
       "        0.        , 0.        , 0.        , 0.34706676, 0.34706676,\n",
       "        0.34706676],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "lsa = TruncatedSVD(2, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(ensemble_matrix)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07624557, 0.27197697])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>be</th>\n",
       "      <th>being</th>\n",
       "      <th>bit</th>\n",
       "      <th>business</th>\n",
       "      <th>enhancing</th>\n",
       "      <th>extending</th>\n",
       "      <th>goes</th>\n",
       "      <th>human</th>\n",
       "      <th>impossibility</th>\n",
       "      <th>...</th>\n",
       "      <th>rejoice</th>\n",
       "      <th>small</th>\n",
       "      <th>the</th>\n",
       "      <th>there</th>\n",
       "      <th>this</th>\n",
       "      <th>toward</th>\n",
       "      <th>us</th>\n",
       "      <th>we</th>\n",
       "      <th>when</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.16308</td>\n",
       "      <td>0.13859</td>\n",
       "      <td>0.29525</td>\n",
       "      <td>0.15263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16308</td>\n",
       "      <td>0.16308</td>\n",
       "      <td>0.13859</td>\n",
       "      <td>0.36978</td>\n",
       "      <td>0.29525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35002</td>\n",
       "      <td>0.13859</td>\n",
       "      <td>0.15263</td>\n",
       "      <td>0.15263</td>\n",
       "      <td>0.15263</td>\n",
       "      <td>0.13859</td>\n",
       "      <td>0.13859</td>\n",
       "      <td>0.13859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>0.33940</td>\n",
       "      <td>-0.15658</td>\n",
       "      <td>0.08931</td>\n",
       "      <td>-0.16285</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.33940</td>\n",
       "      <td>0.33940</td>\n",
       "      <td>-0.15658</td>\n",
       "      <td>0.34588</td>\n",
       "      <td>0.08931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.05428</td>\n",
       "      <td>-0.15658</td>\n",
       "      <td>-0.16285</td>\n",
       "      <td>-0.16285</td>\n",
       "      <td>-0.16285</td>\n",
       "      <td>-0.15658</td>\n",
       "      <td>-0.15658</td>\n",
       "      <td>-0.15658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 and       be    being      bit  business  enhancing  \\\n",
       "component_1  0.16308  0.13859  0.29525  0.15263       0.0    0.16308   \n",
       "component_2  0.33940 -0.15658  0.08931 -0.16285      -0.0    0.33940   \n",
       "\n",
       "             extending     goes    human  impossibility   ...     rejoice  \\\n",
       "component_1    0.16308  0.13859  0.36978        0.29525   ...         0.0   \n",
       "component_2    0.33940 -0.15658  0.34588        0.08931   ...        -0.0   \n",
       "\n",
       "             small      the    there     this   toward       us       we  \\\n",
       "component_1    0.0  0.35002  0.13859  0.15263  0.15263  0.15263  0.13859   \n",
       "component_2   -0.0 -0.05428 -0.15658 -0.16285 -0.16285 -0.16285 -0.15658   \n",
       "\n",
       "                when     will  \n",
       "component_1  0.13859  0.13859  \n",
       "component_2 -0.15658 -0.15658  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(lsa.components_.round(5),\n",
    "             index = [\"component_1\",\"component_2\"],columns = ensemble_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(dtm_lsa.round(5), index = ensemble, columns = [\"component_1\",\"component_2\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the impossibility of being human</th>\n",
       "      <td>0.97009</td>\n",
       "      <td>0.24273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moving this little bit of light toward us</th>\n",
       "      <td>0.74975</td>\n",
       "      <td>-0.66173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           component_1  component_2\n",
       "the impossibility of being human               0.97009      0.24273\n",
       "moving this little bit of light toward us      0.74975     -0.66173"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.nlargest(2, 'component_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>extending and enhancing human life</th>\n",
       "      <td>0.50227</td>\n",
       "      <td>0.86471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the impossibility of being human</th>\n",
       "      <td>0.97009</td>\n",
       "      <td>0.24273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    component_1  component_2\n",
       "extending and enhancing human life      0.50227      0.86471\n",
       "the impossibility of being human        0.97009      0.24273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.nlargest(2, 'component_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.nlargest(2, 'component_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extending and enhancing human life'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the impossibility of being human'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((len(df4.index[1].split())+len(df4.index[1].split()))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('impossibility', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('human', 'JJ')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(df4.index[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extending', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('enhancing', 'VBG'),\n",
       " ('human', 'JJ'),\n",
       " ('life', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(df4.index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/aug18slogan.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['SLOGAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.fit(X)\n",
    "X_matrix = nlp.matrix\n",
    "X_columns = nlp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
